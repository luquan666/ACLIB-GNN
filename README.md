# ACLIB-GNN：Incorporating Adversarial Causal Learning with Information Bottlenecks for Interpretable Graph Neural Networks
This is the official code for the implementation of "ACLIB-GNN：Incorporating Adversarial Causal Learning with Information Bottlenecks for Interpretable Graph Neural Networks"
## Table of contents
* [Overview](#overview)
* [Installation](#installation)
* [Run ACLIB-GNN](#run-leci)
* [Citing LECI](#citing-leci)
* [License](#license)
* [Contact](#contact)

## Overview

In this work, we propose to simultaneously incorporate label and environment causal independence (LECI) to 
release the potential of pre-collected environment information in graph tasks, thereby addressing the challenges faced by prior methods on identifying 
causal/invariant subgraphs. We further develop an adversarial training strategy to jointly optimize these two properties for 
causal subgraph discovery with theoretical guarantees.
